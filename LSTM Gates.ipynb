{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "133e31b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Library\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "056dd460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forget Gate Activation\n",
      "\n",
      "[[0.09958527 0.98827425 0.07167689 0.1558788 ]\n",
      " [0.04493768 0.94296697 0.00372372 0.29403113]]\n"
     ]
    }
   ],
   "source": [
    "# Sigmoid Activation Function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Forget Gate\n",
    "def forget_gate(current_input_f, hidden_prev_f, bias_f, weight_f):\n",
    "    # Concatenate the previous and current input\n",
    "    concat = np.concatenate((current_input_f, hidden_prev_f), axis = 1)\n",
    "    # Calculate the forget gate\n",
    "    forget_gate = sigmoid(np.dot(concat, weight_f) + bias_f)\n",
    "    return forget_gate\n",
    "\n",
    "units = 4\n",
    "features = 8\n",
    "batch_size = 2\n",
    "\n",
    "current_input_f = np.random.randn(batch_size, features)\n",
    "hidden_prev_f = np.random.randn(batch_size, units)\n",
    "\n",
    "bias_f = np.random.randn(1, units)\n",
    "weight_f = np.random.randn(features + units, units)\n",
    "\n",
    "f_t = forget_gate(current_input_f, hidden_prev_f, bias_f, weight_f)\n",
    "\n",
    "print('Forget Gate Activation')\n",
    "print('')\n",
    "print(f_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea53aea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Gate Activation\n",
      "\n",
      "[[0.06491067 0.06447558 0.7342667  0.15732028]\n",
      " [0.11836995 0.05176911 0.97709341 0.99033942]]\n",
      "\n",
      "Candidate State\n",
      "\n",
      "[[ 0.99758758 -0.99957179 -0.99997947  0.99231992]\n",
      " [-0.99027171  0.90469623 -0.99544824  0.93204781]]\n"
     ]
    }
   ],
   "source": [
    "# Sigmoid Activation Function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# TanH Activation Function\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "# Input Gate\n",
    "def input_gate(current_input_i, hidden_prev_i, bias_i, weight_i, weight_c, bias_c):\n",
    "    # Concatenate the previous and current input\n",
    "    concat = np.concatenate((current_input_i, hidden_prev_i), axis = 1)\n",
    "    # Calculate the input gate\n",
    "    input_gate = sigmoid(np.dot(concat, weight_i) + bias_i)\n",
    "    # Calculate candidate cell\n",
    "    candidate_cell = tanh(np.dot(concat, weight_c) + bias_c)\n",
    "    \n",
    "    return input_gate, candidate_cell\n",
    "\n",
    "units = 4\n",
    "features = 8\n",
    "batch_size = 2\n",
    "\n",
    "current_input_i = np.random.randn(batch_size, features)\n",
    "hidden_prev_i = np.random.randn(batch_size, units)\n",
    "\n",
    "bias_i = np.random.randn(1, units)\n",
    "weight_i = np.random.randn(features + units, units)\n",
    "\n",
    "bias_c = np.random.randn(1, units)\n",
    "weight_c = np.random.randn(features + units, units)\n",
    "\n",
    "i_t, c_t = input_gate(current_input_i, hidden_prev_i, bias_i, weight_i, weight_c, bias_c)\n",
    "\n",
    "print('Input Gate Activation')\n",
    "print('')\n",
    "print(i_t)\n",
    "\n",
    "print('')\n",
    "\n",
    "print('Candidate State')\n",
    "print('')\n",
    "print(c_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a166fe54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Gate Activation\n",
      "\n",
      "[[-0.01247277 -0.53977953  0.11343499 -0.33791311]\n",
      " [ 0.22399378 -0.0464726  -0.13359358  0.74558447]]\n"
     ]
    }
   ],
   "source": [
    "# Output Gate\n",
    "\n",
    "def output_gate(current_input_o, hidden_prev_o, bias_o, weight_o, c_t):\n",
    "    # Concatenate the previous and current input\n",
    "    concat = np.concatenate((current_input_o, hidden_prev_o), axis = 1)\n",
    "    # Calculate the output gate\n",
    "    output_gate = sigmoid(np.dot(concat, weight_o) + bias_o)\n",
    "    # Calculate the new hidden state\n",
    "    h_t = output_gate * tanh(c_t)\n",
    "    \n",
    "    return h_t\n",
    "\n",
    "c_t = np.random.randn(batch_size, units)\n",
    "\n",
    "bias_o = np.random.randn(1, units)\n",
    "weight_o = np.random.randn(features + units, units)\n",
    "\n",
    "current_input_o = np.random.randn(batch_size, features)\n",
    "hidden_prev_o = np.random.randn(batch_size, units)\n",
    "\n",
    "h_t = output_gate(current_input_o, hidden_prev_o, bias_o, weight_o, c_t)\n",
    "\n",
    "print('Output Gate Activation')\n",
    "print('')\n",
    "print(h_t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
